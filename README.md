# State-Space-Models

This repository contains materials I prepared on State Space Models for the [Minor “Neural Network Technologies” at FCS, HSE University](https://electives.hse.ru/neuronet/).

## References
- https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state
- https://www.ibm.com/think/topics/mamba-model
- https://github.com/ashaba1in/hse-nlp
- https://youtu.be/luCBXCErkCs?si=oS9g_dWR7GolS-w-
- https://youtu.be/yceNl9C6Ir0?si=MfTPDB3NkrsBn3eD
- https://tridao.me/blog/2024/mamba2-part1-model/
- [HiPPO: Recurrent Memory with Optimal Polynomial Projections](https://arxiv.org/abs/2008.07669) (2020)
- [Efficiently Modeling Long Sequences with Structured State Spaces](https://arxiv.org/abs/2111.00396) (2021)
- [Hungry Hungry Hippos: Towards Language Modeling with State Space Models](https://arxiv.org/abs/2212.14052) (2022)
- [On the Parameterization and Initialization of Diagonal State Space Models](https://arxiv.org/abs/2206.11893) (2022)
- [Mamba: Linear-Time Sequence Modeling with Selective State Spaces](https://arxiv.org/abs/2312.00752) (2023)
- [Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality](https://arxiv.org/abs/2405.21060) (2024)
